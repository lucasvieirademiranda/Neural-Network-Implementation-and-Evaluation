{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(reference_Y, predicted_Y):\n",
    "    \n",
    "    loss = 0\n",
    "    m = reference_Y.shape[0]\n",
    "    \n",
    "    for yt, yp in zip(reference_Y, predicted_Y):\n",
    "        \n",
    "        value = np.sum(yt * np.log(yp) + (1 - yt) * np.log(1 - yp))\n",
    "        loss += value\n",
    "    \n",
    "    loss = -1 * (1 / m) * loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def one_hot_encoding(values):\n",
    "    \n",
    "    classes = np.unique(values).tolist()\n",
    "    \n",
    "    total_classes = len(classes)\n",
    "    \n",
    "    outputs = []\n",
    "    \n",
    "    for value in values:\n",
    "        \n",
    "        index = classes.index(value)\n",
    "        \n",
    "        output = np.zeros(total_classes)\n",
    "        output[index] = 1\n",
    "        \n",
    "        outputs.append(output)\n",
    "        \n",
    "    outputs = np.array(outputs)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_nodes,\n",
    "                 first_hidden_nodes,\n",
    "                 second_hidden_nodes,\n",
    "                 output_nodes,\n",
    "                 learning_rate,\n",
    "                 hidden_activation_function,\n",
    "                 hidden_activation_derivative):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.first_hidden_nodes = first_hidden_nodes\n",
    "        self.second_hidden_nodes = second_hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.bwih = np.random.uniform(-0.1, 0.1, self.first_hidden_nodes).reshape(self.first_hidden_nodes, 1)\n",
    "        self.bwhh = np.random.uniform(-0.1, 0.1, self.second_hidden_nodes).reshape(self.second_hidden_nodes, 1)\n",
    "        self.bwho = np.random.uniform(-0.1, 0.1, self.output_nodes).reshape(self.output_nodes, 1)\n",
    "        \n",
    "        self.wih = np.random.uniform(-0.1, 0.1, self.first_hidden_nodes * self.input_nodes).reshape(self.first_hidden_nodes, self.input_nodes)\n",
    "        self.whh = np.random.uniform(-0.1, 0.1, self.second_hidden_nodes * self.first_hidden_nodes).reshape(self.second_hidden_nodes, self.first_hidden_nodes)\n",
    "        \n",
    "        hidden_nodes = self.first_hidden_nodes if (self.second_hidden_nodes == 0) else self.second_hidden_nodes\n",
    "        \n",
    "        self.who = np.random.uniform(-0.1, 0.1, self.output_nodes * hidden_nodes).reshape(self.output_nodes, hidden_nodes)\n",
    "        \n",
    "        self.hidden_activation_function = hidden_activation_function\n",
    "        self.hidden_activation_derivative = hidden_activation_derivative\n",
    "    \n",
    "    def _softmax(self, x, eps = 1e-15):\n",
    "        \n",
    "        value = np.exp(x - np.max(x)) / np.sum(np.exp(x - np.max(x)))\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    def partial_fit(self, X, y):\n",
    "        \n",
    "        for inputs, targets in zip(X, y):\n",
    "\n",
    "            self._train(inputs, targets)\n",
    "    \n",
    "    def _train(self, inputs, targets):\n",
    "        \n",
    "        if (self.second_hidden_nodes == 0):\n",
    "            \n",
    "            self._one_hidden_layer_train(inputs, targets)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self._two_hidden_layer_train(inputs, targets)\n",
    "        \n",
    "    \n",
    "    def _one_hidden_layer_train(self, inputs, targets):\n",
    "        \n",
    "        inputs = np.array(inputs, ndmin = 2).T\n",
    "        targets = np.array(targets, ndmin = 2).T\n",
    "                \n",
    "        # Executes a Linear Combination\n",
    "        hidden_inputs = np.dot(self.wih, inputs) + (self.bwih * 1)\n",
    "        # Executes Activation Function\n",
    "        hidden_outputs = self.hidden_activation_function(hidden_inputs)\n",
    "        \n",
    "        # Executes a Linear Combination\n",
    "        final_inputs = np.dot(self.who, hidden_outputs) + (self.bwho * 1)\n",
    "        # Executes Activation Function\n",
    "        outputs = self._softmax(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - outputs\n",
    "        \n",
    "        self.bwho += self.learning_rate * output_errors\n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.learning_rate * np.dot(output_errors, hidden_outputs.T)\n",
    "                \n",
    "        # first hidden layer error is the second_hidden_errors, split by weights, recombined at first hidden layer nodes\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        self.bwih += self.learning_rate * (hidden_errors * self.hidden_activation_derivative(hidden_inputs))\n",
    "        \n",
    "        # update the weights for the links between the first hidden layer and input layer\n",
    "        self.wih += self.learning_rate * np.dot((hidden_errors * self.hidden_activation_derivative(hidden_inputs)), inputs.T)\n",
    "        \n",
    "    \n",
    "    def _two_hidden_layer_train(self, inputs, targets):\n",
    "        \n",
    "        inputs = np.array(inputs, ndmin = 2).T\n",
    "        targets = np.array(targets, ndmin = 2).T\n",
    "        \n",
    "        # Executes a Linear Combination\n",
    "        first_hidden_inputs = np.dot(self.wih, inputs) + (self.bwih * 1)\n",
    "        # Executes Activation Function\n",
    "        first_hidden_outputs = self.hidden_activation_function(first_hidden_inputs)\n",
    "        \n",
    "        # Executes a Linear Combination\n",
    "        second_hidden_inputs = np.dot(self.whh, first_hidden_outputs) + (self.bwhh * 1)\n",
    "        # Executes Activation Function\n",
    "        second_hidden_outputs = self.hidden_activation_function(second_hidden_inputs)\n",
    "        \n",
    "        # Executes a Linear Combination\n",
    "        final_inputs = np.dot(self.who, second_hidden_outputs) + (self.bwho * 1)\n",
    "        # Executes Activation Function\n",
    "        outputs  = self._softmax(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - outputs\n",
    "        \n",
    "        self.bwho += self.learning_rate * output_errors\n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.learning_rate * np.dot(output_errors, second_hidden_outputs.T)\n",
    "        \n",
    "        # second hidden layer error is the output_errors, split by weights, recombined at second hidden layer nodes\n",
    "        second_hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        self.bwhh += self.learning_rate * (second_hidden_errors * self.hidden_activation_derivative(second_hidden_inputs))\n",
    "        \n",
    "        # update the weights for the links between the first hidden layer and second hidden layer\n",
    "        self.whh += self.learning_rate * np.dot((second_hidden_errors * self.hidden_activation_derivative(second_hidden_inputs)), first_hidden_outputs.T)\n",
    "        \n",
    "        # first hidden layer error is the second_hidden_errors, split by weights, recombined at first hidden layer nodes\n",
    "        first_hidden_errors = np.dot(self.whh.T, second_hidden_errors)\n",
    "        \n",
    "        self.bwih += self.learning_rate * (first_hidden_errors * self.hidden_activation_derivative(first_hidden_inputs))\n",
    "        \n",
    "        # update the weights for the links between the first hidden layer and input layer\n",
    "        self.wih += self.learning_rate * np.dot((first_hidden_errors * self.hidden_activation_derivative(first_hidden_inputs)), inputs.T)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "        for inputs in X:\n",
    "            \n",
    "            output = self._query(inputs)\n",
    "            \n",
    "            output = np.argmax(output)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            \n",
    "        outputs = np.array(outputs)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "        for inputs in X:\n",
    "            \n",
    "            output = self._query(inputs)\n",
    "            \n",
    "            outputs.append(output)\n",
    "            \n",
    "        outputs = np.array(outputs)\n",
    "        \n",
    "        return outputs\n",
    "        \n",
    "    \n",
    "    def _query(self, inputs):\n",
    "        \n",
    "        result = np.array([])\n",
    "        \n",
    "        if (self.second_hidden_nodes == 0):\n",
    "            \n",
    "            result = self._one_hidden_layer_query(inputs)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            result = self._two_hidden_layer_query(inputs)\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    def _one_hidden_layer_query(self, inputs):\n",
    "        \n",
    "        inputs = np.array(inputs, ndmin = 2).T\n",
    "        \n",
    "        # Executes a Linear Combination\n",
    "        hidden_inputs = np.dot(self.wih, inputs) + (self.bwih * 1)\n",
    "        # Executes Activation Function\n",
    "        hidden_outputs = self.hidden_activation_function(hidden_inputs)\n",
    "        \n",
    "        # Executes a Linear Combination\n",
    "        final_inputs = np.dot(self.who, hidden_outputs) + (self.bwho * 1)\n",
    "        # Executes Activation Function\n",
    "        final_outputs  = self._softmax(final_inputs)\n",
    "        \n",
    "        return final_outputs.ravel()\n",
    "    \n",
    "    def _two_hidden_layer_query(self, inputs):\n",
    "        \n",
    "        inputs = np.array(inputs, ndmin = 2).T\n",
    "        \n",
    "        # Executes a Linear Combination\n",
    "        first_hidden_inputs = np.dot(self.wih, inputs) + (self.bwih * 1)\n",
    "        # Executes Activation Function\n",
    "        first_hidden_outputs = self.hidden_activation_function(first_hidden_inputs)\n",
    "        \n",
    "        # Executes a Linear Combination\n",
    "        second_hidden_inputs = np.dot(self.whh, first_hidden_outputs) + (self.bwhh * 1)\n",
    "        # Executes Activation Function\n",
    "        second_hidden_outputs = self.hidden_activation_function(second_hidden_inputs)\n",
    "        \n",
    "        # Executes a Linear Combination\n",
    "        final_inputs = np.dot(self.who, second_hidden_outputs) + (self.bwho * 1)\n",
    "        # Executes Activation Function\n",
    "        final_outputs  = self._softmax(final_inputs)\n",
    "        \n",
    "        return final_outputs.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_data = 200\n",
    "\n",
    "X = np.random.uniform(0, 10, size = (100, 2))\n",
    "\n",
    "y = [ int(((i + j) / 2) >= 5) for i, j in X ]\n",
    "\n",
    "color = [ 'red' if i == 0 else 'blue' for i in y ]\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], color = color)\n",
    "\n",
    "plt.xticks()\n",
    "plt.yticks()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 0.8\n",
    "\n",
    "total = X.shape[0]\n",
    "\n",
    "training_size = round(total * training_size)\n",
    "validation_size = total - training_size\n",
    "\n",
    "training_X = X[:training_size]\n",
    "validation_X = X[training_size:]\n",
    "\n",
    "training_y = y[:training_size]\n",
    "validation_y = y[training_size:]\n",
    "\n",
    "encoded_training_Y = one_hot_encoding(training_y)\n",
    "encoded_validation_Y = one_hot_encoding(validation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logística\n",
    "#hidden_activation_function = lambda x : 1 / (1 + np.exp(-x))\n",
    "#hidden_activation_derivative = lambda x : hidden_activation_function(x) * (1 - hidden_activation_function(x))\n",
    "\n",
    "# ReLU\n",
    "hidden_activation_function = lambda x : np.maximum(x, 0) \n",
    "hidden_activation_derivative = lambda x : 1 * (x > 0)\n",
    "\n",
    "# Tangente Hiperbólica\n",
    "#hidden_activation_function = lambda x : np.tanh(x)\n",
    "#hidden_activation_derivative = lambda x : 1.0 - np.tanh(x) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Loss: 1.2615667611162922 Validation Loss: 1.3437733572182289 Time: 0.009021997451782227s\n",
      "Epoch: 2 Training Loss: 1.164087686697736 Validation Loss: 1.2925673049642359 Time: 0.010026693344116211s\n",
      "Epoch: 3 Training Loss: 1.1148849455962466 Validation Loss: 1.242662960209485 Time: 0.0070531368255615234s\n",
      "Epoch: 4 Training Loss: 1.070608766541783 Validation Loss: 1.1954045467820298 Time: 0.008020639419555664s\n",
      "Epoch: 5 Training Loss: 1.029109529145207 Validation Loss: 1.1515178926462528 Time: 0.008998632431030273s\n",
      "Epoch: 6 Training Loss: 0.9901919310278379 Validation Loss: 1.1110512670727963 Time: 0.008044719696044922s\n",
      "Epoch: 7 Training Loss: 0.9536697415297115 Validation Loss: 1.073468059775372 Time: 0.008995294570922852s\n",
      "Epoch: 8 Training Loss: 0.9193696998245979 Validation Loss: 1.0385105871307914 Time: 0.007046937942504883s\n",
      "Epoch: 9 Training Loss: 0.8871488609339843 Validation Loss: 1.0059499208645082 Time: 0.008029699325561523s\n",
      "Epoch: 10 Training Loss: 0.8568899748761241 Validation Loss: 0.9755899859210756 Time: 0.0010542869567871094s\n",
      "Epoch: 11 Training Loss: 0.828489558922588 Validation Loss: 0.9472608910565721 Time: 0.0s\n",
      "Epoch: 12 Training Loss: 0.8018477376753611 Validation Loss: 0.9208105072023548 Time: 0.01562786102294922s\n",
      "Epoch: 13 Training Loss: 0.7768626957441875 Validation Loss: 0.8960980692592694 Time: 0.0s\n",
      "Epoch: 14 Training Loss: 0.7534292035338939 Validation Loss: 0.8729904933686928 Time: 0.015625715255737305s\n",
      "Epoch: 15 Training Loss: 0.7314004257275375 Validation Loss: 0.8513290795953043 Time: 0.0s\n",
      "Epoch: 16 Training Loss: 0.7107920680587965 Validation Loss: 0.8310788124256723 Time: 0.015626192092895508s\n",
      "Epoch: 17 Training Loss: 0.6914264693953653 Validation Loss: 0.8120815895088104 Time: 0.0s\n",
      "Epoch: 18 Training Loss: 0.6731977735584862 Validation Loss: 0.7942262749717179 Time: 0.01562666893005371s\n",
      "Epoch: 19 Training Loss: 0.6560067583471332 Validation Loss: 0.7774095639925941 Time: 0.0s\n",
      "Epoch: 20 Training Loss: 0.639761416719623 Validation Loss: 0.7615359519721664 Time: 0.01562643051147461s\n",
      "Epoch: 21 Training Loss: 0.6243771385634167 Validation Loss: 0.7465175312024971 Time: 0.0s\n",
      "Epoch: 22 Training Loss: 0.6097766159617888 Validation Loss: 0.7322736652571002 Time: 0.015626907348632812s\n",
      "Epoch: 23 Training Loss: 0.5958895729860946 Validation Loss: 0.7187305896833953 Time: 0.0s\n",
      "Epoch: 24 Training Loss: 0.5826523950370108 Validation Loss: 0.7058209781450318 Time: 0.01562666893005371s\n",
      "Epoch: 25 Training Loss: 0.570007710571072 Validation Loss: 0.6934835030060911 Time: 0.0s\n",
      "Epoch: 26 Training Loss: 0.5579039604146175 Validation Loss: 0.6816624101587943 Time: 0.01562643051147461s\n",
      "Epoch: 27 Training Loss: 0.5462949765717695 Validation Loss: 0.6703071203396037 Time: 0.011267423629760742s\n",
      "Epoch: 28 Training Loss: 0.5349403150856843 Validation Loss: 0.6591104210896437 Time: 0.008021354675292969s\n",
      "Epoch: 29 Training Loss: 0.5243503631517354 Validation Loss: 0.6487001281438963 Time: 0.01000070571899414s\n",
      "Epoch: 30 Training Loss: 0.5141207748085618 Validation Loss: 0.6386120952766066 Time: 0.008021354675292969s\n",
      "Epoch: 31 Training Loss: 0.5042619979996887 Validation Loss: 0.6288273453009188 Time: 0.008021354675292969s\n",
      "Epoch: 32 Training Loss: 0.4947443576657093 Validation Loss: 0.6193224377662152 Time: 0.008021354675292969s\n",
      "Epoch: 33 Training Loss: 0.4855342322133338 Validation Loss: 0.6100736051423743 Time: 0.0041217803955078125s\n",
      "Epoch: 34 Training Loss: 0.476613920490785 Validation Loss: 0.6010586200350118 Time: 0.0s\n",
      "Epoch: 35 Training Loss: 0.4679678765507423 Validation Loss: 0.5922575495893808 Time: 0.015626192092895508s\n",
      "Epoch: 36 Training Loss: 0.4595358506376491 Validation Loss: 0.5834351743742411 Time: 0.0s\n",
      "Epoch: 37 Training Loss: 0.4516986033998895 Validation Loss: 0.5753634627217078 Time: 0.01565098762512207s\n",
      "Epoch: 38 Training Loss: 0.44402546596507425 Validation Loss: 0.5673871871282067 Time: 0.0s\n",
      "Epoch: 39 Training Loss: 0.43656135994009704 Validation Loss: 0.5595522094044748 Time: 0.0s\n",
      "Epoch: 40 Training Loss: 0.4291369058681266 Validation Loss: 0.5517083962042311 Time: 0.015603303909301758s\n",
      "Epoch: 41 Training Loss: 0.42214006324335585 Validation Loss: 0.5443746952230301 Time: 0.01562666893005371s\n",
      "Epoch: 42 Training Loss: 0.4154789214845659 Validation Loss: 0.5372280140775788 Time: 0.0s\n",
      "Epoch: 43 Training Loss: 0.4089719027429686 Validation Loss: 0.5301462803361844 Time: 0.015626907348632812s\n",
      "Epoch: 44 Training Loss: 0.4027928194334305 Validation Loss: 0.5233654017919444 Time: 0.0s\n",
      "Epoch: 45 Training Loss: 0.39684738848308876 Validation Loss: 0.5170333871861995 Time: 0.015625715255737305s\n",
      "Epoch: 46 Training Loss: 0.3911346263560061 Validation Loss: 0.5109233547852169 Time: 0.0s\n",
      "Epoch: 47 Training Loss: 0.38569204241731353 Validation Loss: 0.5049966005501658 Time: 0.015626192092895508s\n",
      "Epoch: 48 Training Loss: 0.3804560011144224 Validation Loss: 0.4992040944615157 Time: 0.0s\n",
      "Epoch: 49 Training Loss: 0.375428902522814 Validation Loss: 0.49354859044760935 Time: 0.0s\n",
      "Epoch: 50 Training Loss: 0.3711689801951653 Validation Loss: 0.48854705504857937 Time: 0.01562666893005371s\n",
      "Epoch: 51 Training Loss: 0.36676671251464926 Validation Loss: 0.4832515009026109 Time: 0.0s\n",
      "Epoch: 52 Training Loss: 0.36407073097287046 Validation Loss: 0.47938626082136954 Time: 0.02077507972717285s\n",
      "Epoch: 53 Training Loss: 0.35881217199617615 Validation Loss: 0.4731217536204946 Time: 0.0030465126037597656s\n",
      "Epoch: 54 Training Loss: 0.3562130878975239 Validation Loss: 0.4692316009306036 Time: 0.015257120132446289s\n",
      "Epoch: 55 Training Loss: 0.3512966184028629 Validation Loss: 0.4631710187495154 Time: 0.009048938751220703s\n",
      "Epoch: 56 Training Loss: 0.34900854885302107 Validation Loss: 0.45952735734788175 Time: 0.009029865264892578s\n",
      "Epoch: 57 Training Loss: 0.3445191048900399 Validation Loss: 0.4537614705910059 Time: 0.008992671966552734s\n",
      "Epoch: 58 Training Loss: 0.34254904909705386 Validation Loss: 0.450357335599528 Time: 0.008020877838134766s\n",
      "Epoch: 59 Training Loss: 0.33853071665721235 Validation Loss: 0.44493047259578006 Time: 0.008021354675292969s\n",
      "Epoch: 60 Training Loss: 0.33688756671810044 Validation Loss: 0.4417596837665058 Time: 0.0070188045501708984s\n",
      "Epoch: 61 Training Loss: 0.3333928803166533 Validation Loss: 0.4367279126989574 Time: 0.0070188045501708984s\n",
      "Epoch: 62 Training Loss: 0.3320980089717605 Validation Loss: 0.4337978884408636 Time: 0.00909423828125s\n",
      "Epoch: 63 Training Loss: 0.3291907869058701 Validation Loss: 0.42923211476059486 Time: 0.0s\n",
      "Epoch: 64 Training Loss: 0.32828072398072844 Validation Loss: 0.42656721194375513 Time: 0.015626907348632812s\n",
      "Epoch: 65 Training Loss: 0.32689852708408673 Validation Loss: 0.4233143406503633 Time: 0.0s\n",
      "Epoch: 66 Training Loss: 0.32476051928352967 Validation Loss: 0.41927898691501736 Time: 0.0s\n",
      "Epoch: 67 Training Loss: 0.3245073644737444 Validation Loss: 0.41707469466558234 Time: 0.01562666893005371s\n",
      "Epoch: 68 Training Loss: 0.32401466829989434 Validation Loss: 0.4145344183870996 Time: 0.0s\n",
      "Epoch: 69 Training Loss: 0.3232872101926609 Validation Loss: 0.4118545240280114 Time: 0.01562666893005371s\n",
      "Epoch: 70 Training Loss: 0.32394677108690056 Validation Loss: 0.41037823448340965 Time: 0.0s\n",
      "Epoch: 71 Training Loss: 0.32458770736084946 Validation Loss: 0.4088143397949464 Time: 0.015626907348632812s\n",
      "Epoch: 72 Training Loss: 0.3254192188533753 Validation Loss: 0.40763628930525364 Time: 0.0s\n",
      "Epoch: 73 Training Loss: 0.32726016404277025 Validation Loss: 0.4071682877319058 Time: 0.01562643051147461s\n",
      "Epoch: 74 Training Loss: 0.3293832540099357 Validation Loss: 0.40697447238432416 Time: 0.0s\n",
      "Epoch: 75 Training Loss: 0.33218421055047453 Validation Loss: 0.4078000854812248 Time: 0.01562666893005371s\n",
      "Epoch: 76 Training Loss: 0.33562112584575615 Validation Loss: 0.4088114144510951 Time: 0.0s\n",
      "Epoch: 77 Training Loss: 0.34004403492852553 Validation Loss: 0.4113464856000456 Time: 0.01562643051147461s\n",
      "Epoch: 78 Training Loss: 0.34484549414893095 Validation Loss: 0.41369432644763243 Time: 0.009407520294189453s\n",
      "Epoch: 79 Training Loss: 0.35058659403751075 Validation Loss: 0.4171610764452505 Time: 0.010001897811889648s\n",
      "Epoch: 80 Training Loss: 0.3580042508523644 Validation Loss: 0.42302681077467413 Time: 0.008022785186767578s\n",
      "Epoch: 81 Training Loss: 0.36547374167364205 Validation Loss: 0.42816253497527257 Time: 0.009022712707519531s\n",
      "Epoch: 82 Training Loss: 0.3753625939541837 Validation Loss: 0.4368461845616003 Time: 0.00902414321899414s\n",
      "Epoch: 83 Training Loss: 0.38512580441048955 Validation Loss: 0.4444804741523014 Time: 0.00902414321899414s\n",
      "Epoch: 84 Training Loss: 0.39807843814075533 Validation Loss: 0.456798542896919 Time: 0.010051488876342773s\n",
      "Epoch: 85 Training Loss: 0.41163906901729624 Validation Loss: 0.46933844407734987 Time: 0.011006593704223633s\n",
      "Epoch: 86 Training Loss: 0.42711325101447284 Validation Loss: 0.48419670945572135 Time: 0.010024070739746094s\n",
      "Epoch: 87 Training Loss: 0.4446576627883868 Validation Loss: 0.5015707256913381 Time: 0.01002812385559082s\n",
      "Epoch: 88 Training Loss: 0.4645447317171792 Validation Loss: 0.5218399919487341 Time: 0.010062456130981445s\n",
      "Epoch: 89 Training Loss: 0.4870012867756761 Validation Loss: 0.5453239538416377 Time: 0.008016109466552734s\n",
      "Epoch: 90 Training Loss: 0.5121407736275314 Validation Loss: 0.5721976423068438 Time: 0.009023427963256836s\n",
      "Epoch: 91 Training Loss: 0.5398307382131762 Validation Loss: 0.602316748877701 Time: 0.012031793594360352s\n",
      "Epoch: 92 Training Loss: 0.5695535363229173 Validation Loss: 0.6350228198759733 Time: 0.011030197143554688s\n",
      "Epoch: 93 Training Loss: 0.6004073978555884 Validation Loss: 0.6691198340282787 Time: 0.009032726287841797s\n",
      "Epoch: 94 Training Loss: 0.6311712528750508 Validation Loss: 0.7030249660989227 Time: 0.008012533187866211s\n",
      "Epoch: 95 Training Loss: 0.6600444403876252 Validation Loss: 0.7346338961422172 Time: 0.009995460510253906s\n",
      "Epoch: 96 Training Loss: 0.6844690416569614 Validation Loss: 0.7610640456873095 Time: 0.01002645492553711s\n",
      "Epoch: 97 Training Loss: 0.7012043874567808 Validation Loss: 0.7785801543554077 Time: 0.008053779602050781s\n",
      "Epoch: 98 Training Loss: 0.7067736994572557 Validation Loss: 0.7831806867544586 Time: 0.010001182556152344s\n",
      "Epoch: 99 Training Loss: 0.6971591226569717 Validation Loss: 0.7702625809941774 Time: 0.0090179443359375s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 Training Loss: 0.6648027474689522 Validation Loss: 0.7339501717797174 Time: 0.011028766632080078s\n",
      "Epoch: 101 Training Loss: 0.4538915276450897 Validation Loss: 0.5188058322522274 Time: 0.009055137634277344s\n",
      "Epoch: 102 Training Loss: 0.6169525054485442 Validation Loss: 0.7099975758937754 Time: 0.00799107551574707s\n",
      "Epoch: 103 Training Loss: 0.6274543808883164 Validation Loss: 0.7361130119984035 Time: 0.009023904800415039s\n",
      "Epoch: 104 Training Loss: 0.4477282349270252 Validation Loss: 0.5292256577898539 Time: 0.010026216506958008s\n",
      "Epoch: 105 Training Loss: 0.2936441517062861 Validation Loss: 0.36043494741730747 Time: 0.009023427963256836s\n",
      "Epoch: 106 Training Loss: 0.4705572814918229 Validation Loss: 0.5510874982653817 Time: 0.009285688400268555s\n",
      "Epoch: 107 Training Loss: 0.4628394254339194 Validation Loss: 0.5446214004284956 Time: 0.0s\n",
      "Epoch: 108 Training Loss: 0.7543092439596124 Validation Loss: 0.9810181394567681 Time: 0.0s\n",
      "Epoch: 109 Training Loss: 1.1910537685603486 Validation Loss: 1.3458494458461434 Time: 0.01562666893005371s\n",
      "Epoch: 110 Training Loss: 5.973952327026827 Validation Loss: 6.229878766402551 Time: 0.0s\n",
      "Epoch: 111 Training Loss: 3.9370836787339236 Validation Loss: 4.6960548814031275 Time: 0.015626192092895508s\n",
      "Epoch: 112 Training Loss: 16.16901425741777 Validation Loss: 14.013594119745722 Time: 0.0s\n",
      "Epoch: 113 Training Loss: inf Validation Loss: 31.74895365183469 Time: 0.01562643051147461s\n",
      "Epoch: 114 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 115 Training Loss: 0.6647210396926877 Validation Loss: 0.43219388621250704 Time: 0.01562666893005371s\n",
      "Epoch: 116 Training Loss: 39.90886616217289 Validation Loss: 32.53453312511505 Time: 0.0s\n",
      "Epoch: 117 Training Loss: nan Validation Loss: nan Time: 0.019939422607421875s\n",
      "Epoch: 118 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 119 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 120 Training Loss: nan Validation Loss: nan Time: 0.010026693344116211s\n",
      "Epoch: 121 Training Loss: nan Validation Loss: nan Time: 0.009023666381835938s\n",
      "Epoch: 122 Training Loss: nan Validation Loss: nan Time: 0.008699655532836914s\n",
      "Epoch: 123 Training Loss: nan Validation Loss: nan Time: 0.009023666381835938s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\unicamp\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\envs\\unicamp\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124 Training Loss: nan Validation Loss: nan Time: 0.01002645492553711s\n",
      "Epoch: 125 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 126 Training Loss: nan Validation Loss: nan Time: 0.011029958724975586s\n",
      "Epoch: 127 Training Loss: nan Validation Loss: nan Time: 0.009023189544677734s\n",
      "Epoch: 128 Training Loss: nan Validation Loss: nan Time: 0.008022308349609375s\n",
      "Epoch: 129 Training Loss: nan Validation Loss: nan Time: 0.010025978088378906s\n",
      "Epoch: 130 Training Loss: nan Validation Loss: nan Time: 0.009023666381835938s\n",
      "Epoch: 131 Training Loss: nan Validation Loss: nan Time: 0.00902557373046875s\n",
      "Epoch: 132 Training Loss: nan Validation Loss: nan Time: 0.011028528213500977s\n",
      "Epoch: 133 Training Loss: nan Validation Loss: nan Time: 0.012031078338623047s\n",
      "Epoch: 134 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 135 Training Loss: nan Validation Loss: nan Time: 0.010026216506958008s\n",
      "Epoch: 136 Training Loss: nan Validation Loss: nan Time: 0.009023904800415039s\n",
      "Epoch: 137 Training Loss: nan Validation Loss: nan Time: 0.010026693344116211s\n",
      "Epoch: 138 Training Loss: nan Validation Loss: nan Time: 0.011028289794921875s\n",
      "Epoch: 139 Training Loss: nan Validation Loss: nan Time: 0.010026693344116211s\n",
      "Epoch: 140 Training Loss: nan Validation Loss: nan Time: 0.010031461715698242s\n",
      "Epoch: 141 Training Loss: nan Validation Loss: nan Time: 0.010013341903686523s\n",
      "Epoch: 142 Training Loss: nan Validation Loss: nan Time: 0.011027097702026367s\n",
      "Epoch: 143 Training Loss: nan Validation Loss: nan Time: 0.010027170181274414s\n",
      "Epoch: 144 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 145 Training Loss: nan Validation Loss: nan Time: 0.010026216506958008s\n",
      "Epoch: 146 Training Loss: nan Validation Loss: nan Time: 0.010027170181274414s\n",
      "Epoch: 147 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 148 Training Loss: nan Validation Loss: nan Time: 0.009022712707519531s\n",
      "Epoch: 149 Training Loss: nan Validation Loss: nan Time: 0.009023904800415039s\n",
      "Epoch: 150 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 151 Training Loss: nan Validation Loss: nan Time: 0.009055137634277344s\n",
      "Epoch: 152 Training Loss: nan Validation Loss: nan Time: 0.0021142959594726562s\n",
      "Epoch: 153 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 154 Training Loss: nan Validation Loss: nan Time: 0.01563429832458496s\n",
      "Epoch: 155 Training Loss: nan Validation Loss: nan Time: 0.015619277954101562s\n",
      "Epoch: 156 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 157 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 158 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 159 Training Loss: nan Validation Loss: nan Time: 0.015625953674316406s\n",
      "Epoch: 160 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 161 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 162 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 163 Training Loss: nan Validation Loss: nan Time: 0.018730878829956055s\n",
      "Epoch: 164 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 165 Training Loss: nan Validation Loss: nan Time: 0.010026216506958008s\n",
      "Epoch: 166 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 167 Training Loss: nan Validation Loss: nan Time: 0.01005101203918457s\n",
      "Epoch: 168 Training Loss: nan Validation Loss: nan Time: 0.008028507232666016s\n",
      "Epoch: 169 Training Loss: nan Validation Loss: nan Time: 0.007990360260009766s\n",
      "Epoch: 170 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 171 Training Loss: nan Validation Loss: nan Time: 0.008021116256713867s\n",
      "Epoch: 172 Training Loss: nan Validation Loss: nan Time: 0.009024381637573242s\n",
      "Epoch: 173 Training Loss: nan Validation Loss: nan Time: 0.009023666381835938s\n",
      "Epoch: 174 Training Loss: nan Validation Loss: nan Time: 0.009023904800415039s\n",
      "Epoch: 175 Training Loss: nan Validation Loss: nan Time: 0.00802159309387207s\n",
      "Epoch: 176 Training Loss: nan Validation Loss: nan Time: 0.008046627044677734s\n",
      "Epoch: 177 Training Loss: nan Validation Loss: nan Time: 0.01000213623046875s\n",
      "Epoch: 178 Training Loss: nan Validation Loss: nan Time: 0.008020639419555664s\n",
      "Epoch: 179 Training Loss: nan Validation Loss: nan Time: 0.009055852890014648s\n",
      "Epoch: 180 Training Loss: nan Validation Loss: nan Time: 0.009995460510253906s\n",
      "Epoch: 181 Training Loss: nan Validation Loss: nan Time: 0.008020639419555664s\n",
      "Epoch: 182 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 183 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 184 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 185 Training Loss: nan Validation Loss: nan Time: 0.008020877838134766s\n",
      "Epoch: 186 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 187 Training Loss: nan Validation Loss: nan Time: 0.009024620056152344s\n",
      "Epoch: 188 Training Loss: nan Validation Loss: nan Time: 0.010025978088378906s\n",
      "Epoch: 189 Training Loss: nan Validation Loss: nan Time: 0.011029958724975586s\n",
      "Epoch: 190 Training Loss: nan Validation Loss: nan Time: 0.00905752182006836s\n",
      "Epoch: 191 Training Loss: nan Validation Loss: nan Time: 0.008990764617919922s\n",
      "Epoch: 192 Training Loss: nan Validation Loss: nan Time: 0.009023904800415039s\n",
      "Epoch: 193 Training Loss: nan Validation Loss: nan Time: 0.009060859680175781s\n",
      "Epoch: 194 Training Loss: nan Validation Loss: nan Time: 0.008991479873657227s\n",
      "Epoch: 195 Training Loss: nan Validation Loss: nan Time: 0.010051727294921875s\n",
      "Epoch: 196 Training Loss: nan Validation Loss: nan Time: 0.009032011032104492s\n",
      "Epoch: 197 Training Loss: nan Validation Loss: nan Time: 0.009992361068725586s\n",
      "Epoch: 198 Training Loss: nan Validation Loss: nan Time: 0.011033058166503906s\n",
      "Epoch: 199 Training Loss: nan Validation Loss: nan Time: 0.010055065155029297s\n",
      "Epoch: 200 Training Loss: nan Validation Loss: nan Time: 0.009994745254516602s\n",
      "Epoch: 201 Training Loss: nan Validation Loss: nan Time: 0.010059118270874023s\n",
      "Epoch: 202 Training Loss: nan Validation Loss: nan Time: 0.009017229080200195s\n",
      "Epoch: 203 Training Loss: nan Validation Loss: nan Time: 0.01003575325012207s\n",
      "Epoch: 204 Training Loss: nan Validation Loss: nan Time: 0.010028600692749023s\n",
      "Epoch: 205 Training Loss: nan Validation Loss: nan Time: 0.01002049446105957s\n",
      "Epoch: 206 Training Loss: nan Validation Loss: nan Time: 0.010060787200927734s\n",
      "Epoch: 207 Training Loss: nan Validation Loss: nan Time: 0.010997295379638672s\n",
      "Epoch: 208 Training Loss: nan Validation Loss: nan Time: 0.011001110076904297s\n",
      "Epoch: 209 Training Loss: nan Validation Loss: nan Time: 0.009023666381835938s\n",
      "Epoch: 210 Training Loss: nan Validation Loss: nan Time: 0.011060953140258789s\n",
      "Epoch: 211 Training Loss: nan Validation Loss: nan Time: 0.009995698928833008s\n",
      "Epoch: 212 Training Loss: nan Validation Loss: nan Time: 0.010051488876342773s\n",
      "Epoch: 213 Training Loss: nan Validation Loss: nan Time: 0.008999347686767578s\n",
      "Epoch: 214 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 215 Training Loss: nan Validation Loss: nan Time: 0.003232240676879883s\n",
      "Epoch: 216 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 217 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 218 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 219 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 220 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 221 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 222 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 223 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 224 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 225 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 226 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 227 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 228 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 229 Training Loss: nan Validation Loss: nan Time: 0.011229753494262695s\n",
      "Epoch: 230 Training Loss: nan Validation Loss: nan Time: 0.011004924774169922s\n",
      "Epoch: 231 Training Loss: nan Validation Loss: nan Time: 0.010026216506958008s\n",
      "Epoch: 232 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 233 Training Loss: nan Validation Loss: nan Time: 0.008021116256713867s\n",
      "Epoch: 234 Training Loss: nan Validation Loss: nan Time: 0.008022069931030273s\n",
      "Epoch: 235 Training Loss: nan Validation Loss: nan Time: 0.008020639419555664s\n",
      "Epoch: 236 Training Loss: nan Validation Loss: nan Time: 0.009050130844116211s\n",
      "Epoch: 237 Training Loss: nan Validation Loss: nan Time: 0.00900411605834961s\n",
      "Epoch: 238 Training Loss: nan Validation Loss: nan Time: 0.01002049446105957s\n",
      "Epoch: 239 Training Loss: nan Validation Loss: nan Time: 0.009055852890014648s\n",
      "Epoch: 240 Training Loss: nan Validation Loss: nan Time: 0.010997772216796875s\n",
      "Epoch: 241 Training Loss: nan Validation Loss: nan Time: 0.009024381637573242s\n",
      "Epoch: 242 Training Loss: nan Validation Loss: nan Time: 0.009023427963256836s\n",
      "Epoch: 243 Training Loss: nan Validation Loss: nan Time: 0.010025978088378906s\n",
      "Epoch: 244 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 245 Training Loss: nan Validation Loss: nan Time: 0.010026216506958008s\n",
      "Epoch: 246 Training Loss: nan Validation Loss: nan Time: 0.009024381637573242s\n",
      "Epoch: 247 Training Loss: nan Validation Loss: nan Time: 0.010027647018432617s\n",
      "Epoch: 248 Training Loss: nan Validation Loss: nan Time: 0.011028766632080078s\n",
      "Epoch: 249 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250 Training Loss: nan Validation Loss: nan Time: 0.010025978088378906s\n",
      "Epoch: 251 Training Loss: nan Validation Loss: nan Time: 0.009024620056152344s\n",
      "Epoch: 252 Training Loss: nan Validation Loss: nan Time: 0.009055614471435547s\n",
      "Epoch: 253 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 254 Training Loss: nan Validation Loss: nan Time: 0.010008096694946289s\n",
      "Epoch: 255 Training Loss: nan Validation Loss: nan Time: 0.01101541519165039s\n",
      "Epoch: 256 Training Loss: nan Validation Loss: nan Time: 0.008021831512451172s\n",
      "Epoch: 257 Training Loss: nan Validation Loss: nan Time: 0.008020877838134766s\n",
      "Epoch: 258 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 259 Training Loss: nan Validation Loss: nan Time: 0.008021831512451172s\n",
      "Epoch: 260 Training Loss: nan Validation Loss: nan Time: 0.009023666381835938s\n",
      "Epoch: 261 Training Loss: nan Validation Loss: nan Time: 0.005074739456176758s\n",
      "Epoch: 262 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 263 Training Loss: nan Validation Loss: nan Time: 0.015626192092895508s\n",
      "Epoch: 264 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 265 Training Loss: nan Validation Loss: nan Time: 0.019728899002075195s\n",
      "Epoch: 266 Training Loss: nan Validation Loss: nan Time: 0.010026931762695312s\n",
      "Epoch: 267 Training Loss: nan Validation Loss: nan Time: 0.009023904800415039s\n",
      "Epoch: 268 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 269 Training Loss: nan Validation Loss: nan Time: 0.006208181381225586s\n",
      "Epoch: 270 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 271 Training Loss: nan Validation Loss: nan Time: 0.015625715255737305s\n",
      "Epoch: 272 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 273 Training Loss: nan Validation Loss: nan Time: 0.01872992515563965s\n",
      "Epoch: 274 Training Loss: nan Validation Loss: nan Time: 0.010027170181274414s\n",
      "Epoch: 275 Training Loss: nan Validation Loss: nan Time: 0.010051488876342773s\n",
      "Epoch: 276 Training Loss: nan Validation Loss: nan Time: 0.008999347686767578s\n",
      "Epoch: 277 Training Loss: nan Validation Loss: nan Time: 0.0032265186309814453s\n",
      "Epoch: 278 Training Loss: nan Validation Loss: nan Time: 0.014296293258666992s\n",
      "Epoch: 279 Training Loss: nan Validation Loss: nan Time: 0.009024620056152344s\n",
      "Epoch: 280 Training Loss: nan Validation Loss: nan Time: 0.010030984878540039s\n",
      "Epoch: 281 Training Loss: nan Validation Loss: nan Time: 0.01002955436706543s\n",
      "Epoch: 282 Training Loss: nan Validation Loss: nan Time: 0.009023427963256836s\n",
      "Epoch: 283 Training Loss: nan Validation Loss: nan Time: 0.010027170181274414s\n",
      "Epoch: 284 Training Loss: nan Validation Loss: nan Time: 0.010027408599853516s\n",
      "Epoch: 285 Training Loss: nan Validation Loss: nan Time: 0.010025739669799805s\n",
      "Epoch: 286 Training Loss: nan Validation Loss: nan Time: 0.011029958724975586s\n",
      "Epoch: 287 Training Loss: nan Validation Loss: nan Time: 0.011046648025512695s\n",
      "Epoch: 288 Training Loss: nan Validation Loss: nan Time: 0.010008811950683594s\n",
      "Epoch: 289 Training Loss: nan Validation Loss: nan Time: 0.00902700424194336s\n",
      "Epoch: 290 Training Loss: nan Validation Loss: nan Time: 0.010023832321166992s\n",
      "Epoch: 291 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 292 Training Loss: nan Validation Loss: nan Time: 0.009023904800415039s\n",
      "Epoch: 293 Training Loss: nan Validation Loss: nan Time: 0.011034965515136719s\n",
      "Epoch: 294 Training Loss: nan Validation Loss: nan Time: 0.01202702522277832s\n",
      "Epoch: 295 Training Loss: nan Validation Loss: nan Time: 0.009023427963256836s\n",
      "Epoch: 296 Training Loss: nan Validation Loss: nan Time: 0.010033130645751953s\n",
      "Epoch: 297 Training Loss: nan Validation Loss: nan Time: 0.010030746459960938s\n",
      "Epoch: 298 Training Loss: nan Validation Loss: nan Time: 0.010017871856689453s\n",
      "Epoch: 299 Training Loss: nan Validation Loss: nan Time: 0.009022712707519531s\n",
      "Epoch: 300 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 301 Training Loss: nan Validation Loss: nan Time: 0.010026693344116211s\n",
      "Epoch: 302 Training Loss: nan Validation Loss: nan Time: 0.009023904800415039s\n",
      "Epoch: 303 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 304 Training Loss: nan Validation Loss: nan Time: 0.009023904800415039s\n",
      "Epoch: 305 Training Loss: nan Validation Loss: nan Time: 0.009176254272460938s\n",
      "Epoch: 306 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 307 Training Loss: nan Validation Loss: nan Time: 0.015626192092895508s\n",
      "Epoch: 308 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 309 Training Loss: nan Validation Loss: nan Time: 0.018706560134887695s\n",
      "Epoch: 310 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 311 Training Loss: nan Validation Loss: nan Time: 0.009409904479980469s\n",
      "Epoch: 312 Training Loss: nan Validation Loss: nan Time: 0.009024620056152344s\n",
      "Epoch: 313 Training Loss: nan Validation Loss: nan Time: 0.009023666381835938s\n",
      "Epoch: 314 Training Loss: nan Validation Loss: nan Time: 0.009023666381835938s\n",
      "Epoch: 315 Training Loss: nan Validation Loss: nan Time: 0.009436368942260742s\n",
      "Epoch: 316 Training Loss: nan Validation Loss: nan Time: 0.009022951126098633s\n",
      "Epoch: 317 Training Loss: nan Validation Loss: nan Time: 0.01002645492553711s\n",
      "Epoch: 318 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 319 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 320 Training Loss: nan Validation Loss: nan Time: 0.006288290023803711s\n",
      "Epoch: 321 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 322 Training Loss: nan Validation Loss: nan Time: 0.015651464462280273s\n",
      "Epoch: 323 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 324 Training Loss: nan Validation Loss: nan Time: 0.015602827072143555s\n",
      "Epoch: 325 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 326 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 327 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 328 Training Loss: nan Validation Loss: nan Time: 0.015625715255737305s\n",
      "Epoch: 329 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 330 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 331 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 332 Training Loss: nan Validation Loss: nan Time: 0.015626192092895508s\n",
      "Epoch: 333 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 334 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 335 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 336 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 337 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 338 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 339 Training Loss: nan Validation Loss: nan Time: 0.015297889709472656s\n",
      "Epoch: 340 Training Loss: nan Validation Loss: nan Time: 0.011030197143554688s\n",
      "Epoch: 341 Training Loss: nan Validation Loss: nan Time: 0.010025501251220703s\n",
      "Epoch: 342 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 343 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 344 Training Loss: nan Validation Loss: nan Time: 0.007109642028808594s\n",
      "Epoch: 345 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 346 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 347 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 348 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 349 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 350 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 351 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 352 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 353 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 354 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 355 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 356 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 357 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 358 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 359 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 360 Training Loss: nan Validation Loss: nan Time: 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 361 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 362 Training Loss: nan Validation Loss: nan Time: 0.018048524856567383s\n",
      "Epoch: 363 Training Loss: nan Validation Loss: nan Time: 0.010026693344116211s\n",
      "Epoch: 364 Training Loss: nan Validation Loss: nan Time: 0.008052587509155273s\n",
      "Epoch: 365 Training Loss: nan Validation Loss: nan Time: 0.008992910385131836s\n",
      "Epoch: 366 Training Loss: nan Validation Loss: nan Time: 0.009023427963256836s\n",
      "Epoch: 367 Training Loss: nan Validation Loss: nan Time: 0.004206180572509766s\n",
      "Epoch: 368 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 369 Training Loss: nan Validation Loss: nan Time: 0.015626192092895508s\n",
      "Epoch: 370 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 371 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 372 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 373 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 374 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 375 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 376 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 377 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 378 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 379 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 380 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 381 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 382 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 383 Training Loss: nan Validation Loss: nan Time: 0.021821975708007812s\n",
      "Epoch: 384 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 385 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 386 Training Loss: nan Validation Loss: nan Time: 0.002157926559448242s\n",
      "Epoch: 387 Training Loss: nan Validation Loss: nan Time: 0.015625715255737305s\n",
      "Epoch: 388 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 389 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 390 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 391 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 392 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 393 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 394 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 395 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 396 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 397 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 398 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 399 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 400 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 401 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 402 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 403 Training Loss: nan Validation Loss: nan Time: 0.01562786102294922s\n",
      "Epoch: 404 Training Loss: nan Validation Loss: nan Time: 0.015625476837158203s\n",
      "Epoch: 405 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 406 Training Loss: nan Validation Loss: nan Time: 0.015627145767211914s\n",
      "Epoch: 407 Training Loss: nan Validation Loss: nan Time: 0.011098384857177734s\n",
      "Epoch: 408 Training Loss: nan Validation Loss: nan Time: 0.011026859283447266s\n",
      "Epoch: 409 Training Loss: nan Validation Loss: nan Time: 0.00902414321899414s\n",
      "Epoch: 410 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 411 Training Loss: nan Validation Loss: nan Time: 0.006223201751708984s\n",
      "Epoch: 412 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 413 Training Loss: nan Validation Loss: nan Time: 0.015626192092895508s\n",
      "Epoch: 414 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 415 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 416 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 417 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 418 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 419 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 420 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 421 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 422 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 423 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 424 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 425 Training Loss: nan Validation Loss: nan Time: 0.015627145767211914s\n",
      "Epoch: 426 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 427 Training Loss: nan Validation Loss: nan Time: 0.015626192092895508s\n",
      "Epoch: 428 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 429 Training Loss: nan Validation Loss: nan Time: 0.01565098762512207s\n",
      "Epoch: 430 Training Loss: nan Validation Loss: nan Time: 0.013521671295166016s\n",
      "Epoch: 431 Training Loss: nan Validation Loss: nan Time: 0.010024785995483398s\n",
      "Epoch: 432 Training Loss: nan Validation Loss: nan Time: 0.008021354675292969s\n",
      "Epoch: 433 Training Loss: nan Validation Loss: nan Time: 0.00902557373046875s\n",
      "Epoch: 434 Training Loss: nan Validation Loss: nan Time: 0.008019447326660156s\n",
      "Epoch: 435 Training Loss: nan Validation Loss: nan Time: 0.009083271026611328s\n",
      "Epoch: 436 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 437 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 438 Training Loss: nan Validation Loss: nan Time: 0.015625953674316406s\n",
      "Epoch: 439 Training Loss: nan Validation Loss: nan Time: 0.015627622604370117s\n",
      "Epoch: 440 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 441 Training Loss: nan Validation Loss: nan Time: 0.015625953674316406s\n",
      "Epoch: 442 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 443 Training Loss: nan Validation Loss: nan Time: 0.015651226043701172s\n",
      "Epoch: 444 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 445 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 446 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 447 Training Loss: nan Validation Loss: nan Time: 0.015603303909301758s\n",
      "Epoch: 448 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 449 Training Loss: nan Validation Loss: nan Time: 0.015626192092895508s\n",
      "Epoch: 450 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 451 Training Loss: nan Validation Loss: nan Time: 0.015627145767211914s\n",
      "Epoch: 452 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 453 Training Loss: nan Validation Loss: nan Time: 0.023586034774780273s\n",
      "Epoch: 454 Training Loss: nan Validation Loss: nan Time: 0.009023427963256836s\n",
      "Epoch: 455 Training Loss: nan Validation Loss: nan Time: 0.010056495666503906s\n",
      "Epoch: 456 Training Loss: nan Validation Loss: nan Time: 0.008993148803710938s\n",
      "Epoch: 457 Training Loss: nan Validation Loss: nan Time: 0.006234884262084961s\n",
      "Epoch: 458 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 459 Training Loss: nan Validation Loss: nan Time: 0.015614509582519531s\n",
      "Epoch: 460 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 461 Training Loss: nan Validation Loss: nan Time: 0.015625715255737305s\n",
      "Epoch: 462 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 463 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 464 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 465 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 466 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 467 Training Loss: nan Validation Loss: nan Time: 0.015626192092895508s\n",
      "Epoch: 468 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 469 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 470 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 471 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 472 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 473 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 474 Training Loss: nan Validation Loss: nan Time: 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 475 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 476 Training Loss: nan Validation Loss: nan Time: 0.016429424285888672s\n",
      "Epoch: 477 Training Loss: nan Validation Loss: nan Time: 0.011029243469238281s\n",
      "Epoch: 478 Training Loss: nan Validation Loss: nan Time: 0.009024381637573242s\n",
      "Epoch: 479 Training Loss: nan Validation Loss: nan Time: 0.006200075149536133s\n",
      "Epoch: 480 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 481 Training Loss: nan Validation Loss: nan Time: 0.015626192092895508s\n",
      "Epoch: 482 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 483 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 484 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 485 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 486 Training Loss: nan Validation Loss: nan Time: 0.015627145767211914s\n",
      "Epoch: 487 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 488 Training Loss: nan Validation Loss: nan Time: 0.015626192092895508s\n",
      "Epoch: 489 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 490 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 491 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 492 Training Loss: nan Validation Loss: nan Time: 0.015626907348632812s\n",
      "Epoch: 493 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 494 Training Loss: nan Validation Loss: nan Time: 0.01562666893005371s\n",
      "Epoch: 495 Training Loss: nan Validation Loss: nan Time: 0.01562643051147461s\n",
      "Epoch: 496 Training Loss: nan Validation Loss: nan Time: 0.0s\n",
      "Epoch: 497 Training Loss: nan Validation Loss: nan Time: 0.015627145767211914s\n",
      "Epoch: 498 Training Loss: nan Validation Loss: nan Time: 0.013645172119140625s\n",
      "Epoch: 499 Training Loss: nan Validation Loss: nan Time: 0.009021282196044922s\n",
      "Epoch: 500 Training Loss: nan Validation Loss: nan Time: 0.009023904800415039s\n",
      "Elapsed Time: 0.07299911578496297mins\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "input_nodes = 2\n",
    "first_hidden_nodes = 2\n",
    "second_hidden_nodes = 0\n",
    "output_nodes = 2\n",
    "learning_rate = 0.01\n",
    "\n",
    "n = NeuralNetwork(input_nodes,\n",
    "                  first_hidden_nodes,\n",
    "                  second_hidden_nodes,\n",
    "                  output_nodes,\n",
    "                  learning_rate,\n",
    "                  hidden_activation_function,\n",
    "                  hidden_activation_derivative)\n",
    "\n",
    "total_start = time.time()\n",
    "\n",
    "training_epochs = []\n",
    "validation_epochs = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    n.partial_fit(training_X, encoded_training_Y)\n",
    "    \n",
    "    predicted_training_y = n.predict_proba(training_X)\n",
    "    predicted_validation_y = n.predict_proba(validation_X)\n",
    "    \n",
    "    training_mean_loss = cross_entropy_loss(encoded_training_Y, predicted_training_y)\n",
    "    validation_mean_loss = cross_entropy_loss(encoded_validation_Y, predicted_validation_y)\n",
    "    \n",
    "    training_epochs.append([i + 1, training_mean_loss])\n",
    "    validation_epochs.append([i + 1, validation_mean_loss])\n",
    "    \n",
    "    finish = time.time()\n",
    "    \n",
    "    print(\"Epoch: \" + str(i + 1) + \" Training Loss: \" + str(training_mean_loss) + \" Validation Loss: \" + str(validation_mean_loss) + \" Time: \" + str((finish - start)) + \"s\")\n",
    "    \n",
    "total_finish = time.time()\n",
    "\n",
    "print(\"Elapsed Time: \" + str((total_finish - total_start) / 60) + \"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_df = pd.DataFrame(data = training_epochs, columns = ['Epoch', 'Cost'])\n",
    "validation_df = pd.DataFrame(data = validation_epochs, columns = ['Epoch', 'Cost'])\n",
    "\n",
    "plt.plot(training_df['Epoch'], training_df['Cost'], linewidth = 1.0, color = 'red')\n",
    "plt.plot(validation_df['Epoch'], validation_df['Cost'], linewidth = 1.0, color = 'blue')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cost')\n",
    "\n",
    "plt.title(\"Cost x Epochs\")\n",
    "plt.legend(['Cost Training', 'Cost Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = n.predict(validation_X)\n",
    "accuracy = accuracy_score(validation_y, y_predicted)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = np.stack([np.random.normal(2, 0.5, 33), np.random.normal(2, 0.5, 33), [0] * 33], axis = 1)\n",
    "x2 = np.stack([np.random.normal(5, 0.5, 33), np.random.normal(8, 0.5, 33), [1] * 33], axis = 1)\n",
    "x3 = np.stack([np.random.normal(8, 0.5, 33), np.random.normal(2, 0.5, 33), [2] * 33], axis = 1)\n",
    "\n",
    "data = np.concatenate((x1, x2, x3))\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "color = []\n",
    "\n",
    "for x1, x2, y in data:\n",
    "    \n",
    "    if (y == 0):\n",
    "        color.append('red')\n",
    "    elif (y == 1):\n",
    "        color.append('green')\n",
    "    else:\n",
    "        color.append('blue')\n",
    "\n",
    "plt.scatter(data[:, 0], data[:, 1], color = color)\n",
    "\n",
    "plt.xticks()\n",
    "plt.yticks()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 0:2]\n",
    "y = data[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 0.8\n",
    "\n",
    "total = X.shape[0]\n",
    "\n",
    "training_size = round(total * training_size)\n",
    "validation_size = total - training_size\n",
    "\n",
    "training_X = X[:training_size]\n",
    "validation_X = X[training_size:]\n",
    "\n",
    "training_y = y[:training_size]\n",
    "validation_y = y[training_size:]\n",
    "\n",
    "encoded_training_Y = one_hot_encoding(training_y)\n",
    "encoded_validation_Y = one_hot_encoding(validation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logística\n",
    "#hidden_activation_function = lambda x : 1 / (1 + np.exp(-x))\n",
    "#hidden_activation_derivative = lambda x : hidden_activation_function(x) * (1 - hidden_activation_function(x))\n",
    "\n",
    "# ReLU\n",
    "hidden_activation_function = lambda x : np.maximum(x, 0) \n",
    "hidden_activation_derivative = lambda x : 1 * (x > 0)\n",
    "\n",
    "# Tangente Hiperbólica\n",
    "#hidden_activation_function = lambda x : np.tanh(x)\n",
    "#hidden_activation_derivative = lambda x : 1.0 - np.tanh(x) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Loss: 1.902329811356405 Validation Loss: 1.9031576529669612 Time: 0.011058330535888672s\n",
      "Epoch: 2 Training Loss: 1.8985313830353434 Validation Loss: 1.9023550194674095 Time: 0.008020639419555664s\n",
      "Epoch: 3 Training Loss: 1.8944605129579226 Validation Loss: 1.900870537181297 Time: 0.009015321731567383s\n",
      "Epoch: 4 Training Loss: 1.8899280901752162 Validation Loss: 1.8985320153506149 Time: 0.012038946151733398s\n",
      "Epoch: 5 Training Loss: 1.8847287263182764 Validation Loss: 1.8954428466255733 Time: 0.01002645492553711s\n",
      "Epoch: 6 Training Loss: 1.878620076537949 Validation Loss: 1.8911416626745243 Time: 0.008020401000976562s\n",
      "Epoch: 7 Training Loss: 1.871314258968085 Validation Loss: 1.8853557257588045 Time: 0.008021831512451172s\n",
      "Epoch: 8 Training Loss: 1.8624901338655167 Validation Loss: 1.8777776251712155 Time: 0.0069849491119384766s\n",
      "Epoch: 9 Training Loss: 1.8517109992763408 Validation Loss: 1.868545492592977 Time: 0.008021354675292969s\n",
      "Epoch: 10 Training Loss: 1.838561048427365 Validation Loss: 1.8567696499648656 Time: 0.00902414321899414s\n",
      "Epoch: 11 Training Loss: 1.822532479881868 Validation Loss: 1.8419164739888019 Time: 0.002050638198852539s\n",
      "Epoch: 12 Training Loss: 1.8030400439808207 Validation Loss: 1.8242412690344016 Time: 0.0s\n",
      "Epoch: 13 Training Loss: 1.7796503835882758 Validation Loss: 1.8023254450065869 Time: 0.03128552436828613s\n",
      "Epoch: 14 Training Loss: 1.7519565924797216 Validation Loss: 1.7754767048174012 Time: 0.015597343444824219s\n",
      "Epoch: 15 Training Loss: 1.7197636305662076 Validation Loss: 1.7448245828457527 Time: 0.0s\n",
      "Epoch: 16 Training Loss: 1.683250409603812 Validation Loss: 1.7080600728096489 Time: 0.015623092651367188s\n",
      "Epoch: 17 Training Loss: 1.6428681692832285 Validation Loss: 1.6655227800170278 Time: 0.0s\n",
      "Epoch: 18 Training Loss: 1.5993673748257944 Validation Loss: 1.6167333836010425 Time: 0.01562643051147461s\n",
      "Epoch: 19 Training Loss: 1.5535058157937078 Validation Loss: 1.5606443998376927 Time: 0.0s\n",
      "Epoch: 20 Training Loss: 1.5061217324850065 Validation Loss: 1.4983915607755245 Time: 0.023726701736450195s\n",
      "Epoch: 21 Training Loss: 1.4579805321433432 Validation Loss: 1.4317699838943967 Time: 0.010026693344116211s\n",
      "Epoch: 22 Training Loss: 1.4096740672854264 Validation Loss: 1.3599046549182756 Time: 0.010044574737548828s\n",
      "Epoch: 23 Training Loss: 1.3617606689102373 Validation Loss: 1.2867700290862691 Time: 0.010008811950683594s\n",
      "Epoch: 24 Training Loss: 1.314858007027646 Validation Loss: 1.2121190167863038 Time: 0.00902414321899414s\n",
      "Epoch: 25 Training Loss: 1.2695007641798426 Validation Loss: 1.1383400468095692 Time: 0.008021354675292969s\n",
      "Epoch: 26 Training Loss: 1.2262239826321428 Validation Loss: 1.0675587500549237 Time: 0.0012912750244140625s\n",
      "Epoch: 27 Training Loss: 1.1854661831878401 Validation Loss: 1.001386605207225 Time: 0.015625953674316406s\n",
      "Epoch: 28 Training Loss: 1.1475077809812104 Validation Loss: 0.9408153395657269 Time: 0.0s\n",
      "Epoch: 29 Training Loss: 1.1124561928812258 Validation Loss: 0.8862504714502599 Time: 0.01562643051147461s\n",
      "Epoch: 30 Training Loss: 1.0802679214255393 Validation Loss: 0.8376348269049049 Time: 0.0s\n",
      "Epoch: 31 Training Loss: 1.0507976540093953 Validation Loss: 0.7949296281226764 Time: 0.015627145767211914s\n",
      "Epoch: 32 Training Loss: 1.0238873135506645 Validation Loss: 0.7565960491572716 Time: 0.0s\n",
      "Epoch: 33 Training Loss: 0.99937759122455 Validation Loss: 0.7229711873813661 Time: 0.01562643051147461s\n",
      "Epoch: 34 Training Loss: 0.9768861822502561 Validation Loss: 0.6935445230321114 Time: 0.0s\n",
      "Epoch: 35 Training Loss: 0.9562104004897494 Validation Loss: 0.667900228066058 Time: 0.015626907348632812s\n",
      "Epoch: 36 Training Loss: 0.9370779424856327 Validation Loss: 0.6448759423507671 Time: 0.015626907348632812s\n",
      "Epoch: 37 Training Loss: 0.9192666582389231 Validation Loss: 0.6240906921625975 Time: 0.0s\n",
      "Epoch: 38 Training Loss: 0.9026146313117395 Validation Loss: 0.6052258151361765 Time: 0.015625953674316406s\n",
      "Epoch: 39 Training Loss: 0.8870268696637233 Validation Loss: 0.5883304154878756 Time: 0.0s\n",
      "Epoch: 40 Training Loss: 0.8723152119185358 Validation Loss: 0.5727966734000398 Time: 0.015626907348632812s\n",
      "Epoch: 41 Training Loss: 0.8584025238269446 Validation Loss: 0.558676724720239 Time: 0.0s\n",
      "Epoch: 42 Training Loss: 0.8451850989343676 Validation Loss: 0.5455775839716069 Time: 0.022153377532958984s\n",
      "Epoch: 43 Training Loss: 0.8326037120398774 Validation Loss: 0.5335260406519067 Time: 0.010027170181274414s\n",
      "Epoch: 44 Training Loss: 0.820563802655973 Validation Loss: 0.522335987779005 Time: 0.010057926177978516s\n",
      "Epoch: 45 Training Loss: 0.8090112521095391 Validation Loss: 0.5119751658900115 Time: 0.008992910385131836s\n",
      "Epoch: 46 Training Loss: 0.7978996947456319 Validation Loss: 0.5022088574608929 Time: 0.010057926177978516s\n",
      "Epoch: 47 Training Loss: 0.7871961391936356 Validation Loss: 0.4929708246423343 Time: 0.005055904388427734s\n",
      "Epoch: 48 Training Loss: 0.7768523986613515 Validation Loss: 0.48422320589493967 Time: 0.0s\n",
      "Epoch: 49 Training Loss: 0.7668260564398712 Validation Loss: 0.4755777679247204 Time: 0.015627384185791016s\n",
      "Epoch: 50 Training Loss: 0.757096140102012 Validation Loss: 0.46724231763525403 Time: 0.0s\n",
      "Epoch: 51 Training Loss: 0.7476585569629761 Validation Loss: 0.45949980683983516 Time: 0.015626192092895508s\n",
      "Epoch: 52 Training Loss: 0.7384752222532015 Validation Loss: 0.45192328403636134 Time: 0.0s\n",
      "Epoch: 53 Training Loss: 0.7295356238394965 Validation Loss: 0.44468341264943395 Time: 0.015626192092895508s\n",
      "Epoch: 54 Training Loss: 0.7208226357288893 Validation Loss: 0.43773994107943887 Time: 0.015626907348632812s\n",
      "Epoch: 55 Training Loss: 0.7123213474388773 Validation Loss: 0.43106002967775015 Time: 0.0s\n",
      "Epoch: 56 Training Loss: 0.7040186670534289 Validation Loss: 0.42461655836142864 Time: 0.01562643051147461s\n",
      "Epoch: 57 Training Loss: 0.6959030165871943 Validation Loss: 0.4183868815555381 Time: 0.0s\n",
      "Epoch: 58 Training Loss: 0.687964092806453 Validation Loss: 0.4123518989363354 Time: 0.01562666893005371s\n",
      "Epoch: 59 Training Loss: 0.6801973302556009 Validation Loss: 0.4066227898359279 Time: 0.0s\n",
      "Epoch: 60 Training Loss: 0.6725847027089848 Validation Loss: 0.4009021316137793 Time: 0.01562666893005371s\n",
      "Epoch: 61 Training Loss: 0.6651287079702085 Validation Loss: 0.3954634750397864 Time: 0.0s\n",
      "Epoch: 62 Training Loss: 0.6578125892953065 Validation Loss: 0.3900225711967509 Time: 0.01562643051147461s\n",
      "Epoch: 63 Training Loss: 0.6506402895861896 Validation Loss: 0.3848430928204193 Time: 0.0s\n",
      "Epoch: 64 Training Loss: 0.6436012363278864 Validation Loss: 0.3797684776768355 Time: 0.023616790771484375s\n",
      "Epoch: 65 Training Loss: 0.6366902151578797 Validation Loss: 0.3747965941196399 Time: 0.009024620056152344s\n",
      "Epoch: 66 Training Loss: 0.6299082447375234 Validation Loss: 0.3700398882923137 Time: 0.010027170181274414s\n",
      "Epoch: 67 Training Loss: 0.6232393962007764 Validation Loss: 0.365240398667732 Time: 0.011028289794921875s\n",
      "Epoch: 68 Training Loss: 0.616691591677059 Validation Loss: 0.360653136741385 Time: 0.009023666381835938s\n",
      "Epoch: 69 Training Loss: 0.6102551883213955 Validation Loss: 0.35613608548892506 Time: 0.003333568572998047s\n",
      "Epoch: 70 Training Loss: 0.6039265623426309 Validation Loss: 0.35169139020930235 Time: 0.0s\n",
      "Epoch: 71 Training Loss: 0.597702424625153 Validation Loss: 0.347319940041545 Time: 0.015626192092895508s\n",
      "Epoch: 72 Training Loss: 0.5915797435430669 Validation Loss: 0.34302176012609664 Time: 0.0s\n",
      "Epoch: 73 Training Loss: 0.585555696857714 Validation Loss: 0.33879628974273296 Time: 0.01562666893005371s\n",
      "Epoch: 74 Training Loss: 0.5796276397832317 Validation Loss: 0.3346425785337474 Time: 0.0s\n",
      "Epoch: 75 Training Loss: 0.5737982725864755 Validation Loss: 0.33062469582890514 Time: 0.01562643051147461s\n",
      "Epoch: 76 Training Loss: 0.5680600963072849 Validation Loss: 0.326661958584731 Time: 0.0s\n",
      "Epoch: 77 Training Loss: 0.5624107796747658 Validation Loss: 0.3227564045532172 Time: 0.020910024642944336s\n",
      "Epoch: 78 Training Loss: 0.5568481703907572 Validation Loss: 0.3189091194595375 Time: 0.0s\n",
      "Epoch: 79 Training Loss: 0.5513709594210268 Validation Loss: 0.3151058236664325 Time: 0.01562643051147461s\n",
      "Epoch: 80 Training Loss: 0.5459762016383243 Validation Loss: 0.31136897305983413 Time: 0.0s\n",
      "Epoch: 81 Training Loss: 0.5406613785749805 Validation Loss: 0.307709967507131 Time: 0.01562666893005371s\n",
      "Epoch: 82 Training Loss: 0.5354268487891263 Validation Loss: 0.3040905596901537 Time: 0.01562809944152832s\n",
      "Epoch: 83 Training Loss: 0.5302697311351926 Validation Loss: 0.3005328558858597 Time: 0.0s\n",
      "Epoch: 84 Training Loss: 0.5251876498075825 Validation Loss: 0.2970483598030632 Time: 0.015625s\n",
      "Epoch: 85 Training Loss: 0.5201811912914699 Validation Loss: 0.29360007982400976 Time: 0.0s\n",
      "Epoch: 86 Training Loss: 0.5152476061897086 Validation Loss: 0.2902096788368762 Time: 0.015626907348632812s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87 Training Loss: 0.5103855360255123 Validation Loss: 0.2868750223614102 Time: 0.015999555587768555s\n",
      "Epoch: 88 Training Loss: 0.5055936557281898 Validation Loss: 0.28359432301906135 Time: 0.010027170181274414s\n",
      "Epoch: 89 Training Loss: 0.5008706740211292 Validation Loss: 0.28036604209705646 Time: 0.009023904800415039s\n",
      "Epoch: 90 Training Loss: 0.4962153338817421 Validation Loss: 0.2771888215841703 Time: 0.01002645492553711s\n",
      "Epoch: 91 Training Loss: 0.4916264126487494 Validation Loss: 0.27406143707554204 Time: 0.01002645492553711s\n",
      "Epoch: 92 Training Loss: 0.48710272170104874 Validation Loss: 0.27098276500667995 Time: 0.009023904800415039s\n",
      "Epoch: 93 Training Loss: 0.48264310576426706 Validation Loss: 0.2679517597438012 Time: 0.009894847869873047s\n",
      "Epoch: 94 Training Loss: 0.47824644193761645 Validation Loss: 0.2649674374625119 Time: 0.010025262832641602s\n",
      "Epoch: 95 Training Loss: 0.4739116385316008 Validation Loss: 0.26202886470654485 Time: 0.009023427963256836s\n",
      "Epoch: 96 Training Loss: 0.46963763379193685 Validation Loss: 0.259144145735319 Time: 0.009024381637573242s\n",
      "Epoch: 97 Training Loss: 0.46542339456763787 Validation Loss: 0.2563081018994069 Time: 0.010026216506958008s\n",
      "Epoch: 98 Training Loss: 0.46126791496565767 Validation Loss: 0.25351539747281604 Time: 0.007137298583984375s\n",
      "Epoch: 99 Training Loss: 0.45717021502195326 Validation Loss: 0.25076520741181424 Time: 0.0s\n",
      "Epoch: 100 Training Loss: 0.4531350110006232 Validation Loss: 0.24810775530188237 Time: 0.01562809944152832s\n",
      "Epoch: 101 Training Loss: 0.44915728404682237 Validation Loss: 0.24548000851101062 Time: 0.0s\n",
      "Epoch: 102 Training Loss: 0.4452346888358112 Validation Loss: 0.24288406089986248 Time: 0.02181386947631836s\n",
      "Epoch: 103 Training Loss: 0.44136620124876663 Validation Loss: 0.24032125899336165 Time: 0.00902414321899414s\n",
      "Epoch: 104 Training Loss: 0.4375508739184159 Validation Loss: 0.23779241611748425 Time: 0.009023666381835938s\n",
      "Epoch: 105 Training Loss: 0.43378781115521003 Validation Loss: 0.2352979659369092 Time: 0.010072469711303711s\n",
      "Epoch: 106 Training Loss: 0.4300761543065301 Validation Loss: 0.23283807205151594 Time: 0.009979248046875s\n",
      "Epoch: 107 Training Loss: 0.4264162960710552 Validation Loss: 0.23041270607201533 Time: 0.0072209835052490234s\n",
      "Epoch: 108 Training Loss: 0.422805862351922 Validation Loss: 0.22803304134997016 Time: 0.011875152587890625s\n",
      "Epoch: 109 Training Loss: 0.4192441194919071 Validation Loss: 0.22572851488496132 Time: 0.00899958610534668s\n",
      "Epoch: 110 Training Loss: 0.4157305550291446 Validation Loss: 0.2234484231410956 Time: 0.0100250244140625s\n",
      "Epoch: 111 Training Loss: 0.41225132237414813 Validation Loss: 0.2211268572334919 Time: 0.009023666381835938s\n",
      "Epoch: 112 Training Loss: 0.40881825873911665 Validation Loss: 0.21884940708645617 Time: 0.010026693344116211s\n",
      "Epoch: 113 Training Loss: 0.4054306645422524 Validation Loss: 0.21661250157413267 Time: 0.010027408599853516s\n",
      "Epoch: 114 Training Loss: 0.4020878740616255 Validation Loss: 0.21441347931067312 Time: 0.010057687759399414s\n",
      "Epoch: 115 Training Loss: 0.39878923251850834 Validation Loss: 0.21225030660698596 Time: 0.008992671966552734s\n",
      "Epoch: 116 Training Loss: 0.39553408899630504 Validation Loss: 0.21012138710022943 Time: 0.004226207733154297s\n",
      "Epoch: 117 Training Loss: 0.3923261871761608 Validation Loss: 0.2080254321027607 Time: 0.0s\n",
      "Epoch: 118 Training Loss: 0.38916078306520097 Validation Loss: 0.2059613716464695 Time: 0.015627384185791016s\n",
      "Epoch: 119 Training Loss: 0.38604003506993334 Validation Loss: 0.20396488075743463 Time: 0.0s\n",
      "Epoch: 120 Training Loss: 0.38296059992151865 Validation Loss: 0.20198978740957274 Time: 0.015625953674316406s\n",
      "Epoch: 121 Training Loss: 0.37992162436031934 Validation Loss: 0.20003769259654025 Time: 0.0s\n",
      "Epoch: 122 Training Loss: 0.3769223583340261 Validation Loss: 0.1981096103915973 Time: 0.015626192092895508s\n",
      "Epoch: 123 Training Loss: 0.3739621155220301 Validation Loss: 0.19620614254753896 Time: 0.01572561264038086s\n",
      "Epoch: 124 Training Loss: 0.37104025124825984 Validation Loss: 0.19432760187973167 Time: 0.008211374282836914s\n",
      "Epoch: 125 Training Loss: 0.3681561497025741 Validation Loss: 0.19247409900652246 Time: 0.0s\n",
      "Epoch: 126 Training Loss: 0.3653088613632611 Validation Loss: 0.19065663937735056 Time: 0.015626192092895508s\n",
      "Epoch: 127 Training Loss: 0.36249878866144475 Validation Loss: 0.18884853867579607 Time: 0.0s\n",
      "Epoch: 128 Training Loss: 0.35972749099438656 Validation Loss: 0.18710686742454782 Time: 0.01907038688659668s\n",
      "Epoch: 129 Training Loss: 0.3569932733459284 Validation Loss: 0.1853680110395425 Time: 0.009994745254516602s\n",
      "Epoch: 130 Training Loss: 0.3542944806785944 Validation Loss: 0.183660925529109 Time: 0.00902414321899414s\n",
      "Epoch: 131 Training Loss: 0.3516303976641681 Validation Loss: 0.18197079896264157 Time: 0.011060953140258789s\n",
      "Epoch: 132 Training Loss: 0.34900032289600036 Validation Loss: 0.18029915582714048 Time: 0.009024858474731445s\n",
      "Epoch: 133 Training Loss: 0.34640363692095383 Validation Loss: 0.17864698894006914 Time: 0.010001182556152344s\n",
      "Epoch: 134 Training Loss: 0.34383977061847537 Validation Loss: 0.17701491660812568 Time: 0.009048938751220703s\n",
      "Epoch: 135 Training Loss: 0.3413081876418081 Validation Loss: 0.17540329344867636 Time: 0.01002645492553711s\n",
      "Epoch: 136 Training Loss: 0.3388083743397264 Validation Loss: 0.17381228825000375 Time: 0.009030342102050781s\n",
      "Epoch: 137 Training Loss: 0.33633983378581844 Validation Loss: 0.17224193860874312 Time: 0.007987737655639648s\n",
      "Epoch: 138 Training Loss: 0.3339020821387003 Validation Loss: 0.1706921892984212 Time: 0.010026693344116211s\n",
      "Epoch: 139 Training Loss: 0.33149606405887166 Validation Loss: 0.16916291927515248 Time: 0.00902414321899414s\n",
      "Epoch: 140 Training Loss: 0.32912070983830444 Validation Loss: 0.16767951378475365 Time: 0.009023904800415039s\n",
      "Epoch: 141 Training Loss: 0.3267751500093633 Validation Loss: 0.16620997521925082 Time: 0.00902414321899414s\n",
      "Epoch: 142 Training Loss: 0.32445875158873877 Validation Loss: 0.16475579265166465 Time: 0.009023904800415039s\n",
      "Epoch: 143 Training Loss: 0.32217096348840235 Validation Loss: 0.16331793776229397 Time: 0.009055376052856445s\n",
      "Epoch: 144 Training Loss: 0.31991128477808556 Validation Loss: 0.1618970202755362 Time: 0.008992671966552734s\n",
      "Epoch: 145 Training Loss: 0.31767924705740397 Validation Loss: 0.16049339683754982 Time: 0.00902414321899414s\n",
      "Epoch: 146 Training Loss: 0.31547440431841656 Validation Loss: 0.15910724701441437 Time: 0.009023666381835938s\n",
      "Epoch: 147 Training Loss: 0.31329632691841675 Validation Loss: 0.15773862627630242 Time: 0.009024381637573242s\n",
      "Epoch: 148 Training Loss: 0.3111445978866253 Validation Loss: 0.1563875029578051 Time: 0.01002645492553711s\n",
      "Epoch: 149 Training Loss: 0.30901881060060477 Validation Loss: 0.1550537840929048 Time: 0.009023666381835938s\n",
      "Epoch: 150 Training Loss: 0.30691856729067546 Validation Loss: 0.15373733353366795 Time: 0.010026693344116211s\n",
      "Epoch: 151 Training Loss: 0.3048434780573799 Validation Loss: 0.15243798471518274 Time: 0.010026693344116211s\n",
      "Epoch: 152 Training Loss: 0.30279316021295627 Validation Loss: 0.15115554970014328 Time: 0.008021354675292969s\n",
      "Epoch: 153 Training Loss: 0.3007672378302161 Validation Loss: 0.1498898256312667 Time: 0.010026693344116211s\n",
      "Epoch: 154 Training Loss: 0.2987653414252935 Validation Loss: 0.1486405993708488 Time: 0.00902414321899414s\n",
      "Epoch: 155 Training Loss: 0.29678710772711375 Validation Loss: 0.14740765086632632 Time: 0.010026693344116211s\n",
      "Epoch: 156 Training Loss: 0.2948326484302279 Validation Loss: 0.14619075561515818 Time: 0.009055376052856445s\n",
      "Epoch: 157 Training Loss: 0.2929016056854446 Validation Loss: 0.14498968648835242 Time: 0.008993387222290039s\n",
      "Epoch: 158 Training Loss: 0.29099316025074323 Validation Loss: 0.1438042150934464 Time: 0.010025501251220703s\n",
      "Epoch: 159 Training Loss: 0.28910697155782306 Validation Loss: 0.14263411280357943 Time: 0.00902414321899414s\n",
      "Epoch: 160 Training Loss: 0.28724270471498053 Validation Loss: 0.14147915154186302 Time: 0.009023904800415039s\n",
      "Epoch: 161 Training Loss: 0.28540003041107775 Validation Loss: 0.14033910438431071 Time: 0.008021354675292969s\n",
      "Epoch: 162 Training Loss: 0.2835786248247593 Validation Loss: 0.1392137460265553 Time: 0.008021116256713867s\n",
      "Epoch: 163 Training Loss: 0.28177816953698565 Validation Loss: 0.1381028531469817 Time: 0.00802159309387207s\n",
      "Epoch: 164 Training Loss: 0.2799983514456814 Validation Loss: 0.1370062046900665 Time: 0.0021431446075439453s\n",
      "Epoch: 165 Training Loss: 0.27823886268176057 Validation Loss: 0.1359235820874689 Time: 0.0s\n",
      "Epoch: 166 Training Loss: 0.27649856955136887 Validation Loss: 0.13487566576595186 Time: 0.015639066696166992s\n",
      "Epoch: 167 Training Loss: 0.274778446413072 Validation Loss: 0.13383602089437027 Time: 0.0s\n",
      "Epoch: 168 Training Loss: 0.27307802678839976 Validation Loss: 0.13280595648156493 Time: 0.015613794326782227s\n",
      "Epoch: 169 Training Loss: 0.2713969181268325 Validation Loss: 0.1317863295702955 Time: 0.01562643051147461s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170 Training Loss: 0.26973477274120655 Validation Loss: 0.1307776838294826 Time: 0.010089874267578125s\n",
      "Epoch: 171 Training Loss: 0.2680912716591779 Validation Loss: 0.12978034603278063 Time: 0.009022235870361328s\n",
      "Epoch: 172 Training Loss: 0.26646611532246234 Validation Loss: 0.1287944929762295 Time: 0.008021354675292969s\n",
      "Epoch: 173 Training Loss: 0.26485901803881445 Validation Loss: 0.1278201978059963 Time: 0.011028766632080078s\n",
      "Epoch: 174 Training Loss: 0.2632697045632128 Validation Loss: 0.12685746207322363 Time: 0.00902414321899414s\n",
      "Epoch: 175 Training Loss: 0.2616979079290304 Validation Loss: 0.1259062379228234 Time: 0.009023904800415039s\n",
      "Epoch: 176 Training Loss: 0.2601433680365056 Validation Loss: 0.124966443472326 Time: 0.00902414321899414s\n",
      "Epoch: 177 Training Loss: 0.258605830712713 Validation Loss: 0.12403797349228561 Time: 0.0030815601348876953s\n",
      "Epoch: 178 Training Loss: 0.2570850470717557 Validation Loss: 0.12312070684385773 Time: 0.0s\n",
      "Epoch: 179 Training Loss: 0.2555807730695047 Validation Loss: 0.1222145116758367 Time: 0.01562643051147461s\n",
      "Epoch: 180 Training Loss: 0.25409276918609564 Validation Loss: 0.12131924907101 Time: 0.015651464462280273s\n",
      "Epoch: 181 Training Loss: 0.2526208001931464 Validation Loss: 0.12043477561676144 Time: 0.0s\n",
      "Epoch: 182 Training Loss: 0.25116463497755476 Validation Loss: 0.1195609452271183 Time: 0.015626192092895508s\n",
      "Epoch: 183 Training Loss: 0.24972404640328597 Validation Loss: 0.118697610441951 Time: 0.0s\n",
      "Epoch: 184 Training Loss: 0.24829881119877484 Validation Loss: 0.11784462335928428 Time: 0.0s\n",
      "Epoch: 185 Training Loss: 0.24688870986167502 Validation Loss: 0.1170018363087326 Time: 0.015611648559570312s\n",
      "Epoch: 186 Training Loss: 0.24549352657540505 Validation Loss: 0.11616910234107643 Time: 0.0s\n",
      "Epoch: 187 Training Loss: 0.24411309091084907 Validation Loss: 0.11534627558626763 Time: 0.015618085861206055s\n",
      "Epoch: 188 Training Loss: 0.2427466516750123 Validation Loss: 0.11454414578085559 Time: 0.0s\n",
      "Epoch: 189 Training Loss: 0.24139513942447577 Validation Loss: 0.1137379304568305 Time: 0.015632152557373047s\n",
      "Epoch: 190 Training Loss: 0.2400572657230349 Validation Loss: 0.11295266965010664 Time: 0.015620946884155273s\n",
      "Epoch: 191 Training Loss: 0.23873380610816028 Validation Loss: 0.11216394001925706 Time: 0.0s\n",
      "Epoch: 192 Training Loss: 0.23742358214875767 Validation Loss: 0.11139600287827685 Time: 0.015625953674316406s\n",
      "Epoch: 193 Training Loss: 0.23612734969686955 Validation Loss: 0.11062958398638574 Time: 0.01296854019165039s\n",
      "Epoch: 194 Training Loss: 0.2348439724095349 Validation Loss: 0.1098842422556265 Time: 0.01102900505065918s\n",
      "Epoch: 195 Training Loss: 0.23357419245394107 Validation Loss: 0.10913598136084368 Time: 0.009024620056152344s\n",
      "Epoch: 196 Training Loss: 0.23231690345515763 Validation Loss: 0.10840762696655415 Time: 0.007989645004272461s\n",
      "Epoch: 197 Training Loss: 0.23107285361168756 Validation Loss: 0.10767644051685343 Time: 0.0011982917785644531s\n",
      "Epoch: 198 Training Loss: 0.22984091109723315 Validation Loss: 0.10696468885394682 Time: 0.015626192092895508s\n",
      "Epoch: 199 Training Loss: 0.22862188564020483 Validation Loss: 0.10625015986985298 Time: 0.0s\n",
      "Epoch: 200 Training Loss: 0.22741458745247173 Validation Loss: 0.10555458574115491 Time: 0.01562666893005371s\n",
      "Elapsed Time: 0.03015660047531128mins\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "input_nodes = 2\n",
    "first_hidden_nodes = 3\n",
    "second_hidden_nodes = 0\n",
    "output_nodes = 3\n",
    "learning_rate = 0.001\n",
    "\n",
    "n = NeuralNetwork(input_nodes,\n",
    "                  first_hidden_nodes,\n",
    "                  second_hidden_nodes,\n",
    "                  output_nodes,\n",
    "                  learning_rate,\n",
    "                  hidden_activation_function,\n",
    "                  hidden_activation_derivative)\n",
    "\n",
    "total_start = time.time()\n",
    "\n",
    "training_epochs = []\n",
    "validation_epochs = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    n.partial_fit(training_X, encoded_training_Y)\n",
    "    \n",
    "    predicted_training_y = n.predict_proba(training_X)\n",
    "    predicted_validation_y = n.predict_proba(validation_X)\n",
    "    \n",
    "    training_mean_loss = cross_entropy_loss(encoded_training_Y, predicted_training_y)\n",
    "    validation_mean_loss = cross_entropy_loss(encoded_validation_Y, predicted_validation_y)\n",
    "    \n",
    "    training_epochs.append([i + 1, training_mean_loss])\n",
    "    validation_epochs.append([i + 1, validation_mean_loss])\n",
    "    \n",
    "    finish = time.time()\n",
    "    \n",
    "    print(\"Epoch: \" + str(i + 1) + \" Training Loss: \" + str(training_mean_loss) + \" Validation Loss: \" + str(validation_mean_loss) + \" Time: \" + str((finish - start)) + \"s\")\n",
    "    \n",
    "total_finish = time.time()\n",
    "\n",
    "print(\"Elapsed Time: \" + str((total_finish - total_start) / 60) + \"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_df = pd.DataFrame(data = training_epochs, columns = ['Epoch', 'Cost'])\n",
    "validation_df = pd.DataFrame(data = validation_epochs, columns = ['Epoch', 'Cost'])\n",
    "\n",
    "plt.plot(training_df['Epoch'], training_df['Cost'], linewidth = 1.0, color = 'red')\n",
    "plt.plot(validation_df['Epoch'], validation_df['Cost'], linewidth = 1.0, color = 'blue')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cost')\n",
    "\n",
    "plt.title(\"Cost x Epochs\")\n",
    "plt.legend(['Cost Training', 'Cost Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = n.predict(validation_X)\n",
    "accuracy = accuracy_score(validation_y, y_predicted)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
